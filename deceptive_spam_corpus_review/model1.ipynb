{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of truthfuls reviews  800\n",
      "Number of deceptives reviews  800\n"
     ]
    }
   ],
   "source": [
    "truthful_pos = 'op_spam_v1.4/positive_polarity/truthful_from_TripAdvisor/'\n",
    "truthful_neg = 'op_spam_v1.4/negative_polarity/truthful_from_Web/'\n",
    "\n",
    "deceptive_pos = 'op_spam_v1.4/positive_polarity/deceptive_from_MTurk/'\n",
    "deceptive_neg = 'op_spam_v1.4/negative_polarity/deceptive_from_MTurk/'\n",
    "\n",
    "truthful_reviews_link = []\n",
    "for fold in os.listdir(truthful_pos):\n",
    "    foldLink = os.path.join(truthful_pos, fold)\n",
    "    if os.path.isdir(foldLink):\n",
    "        for f in os.listdir(foldLink):\n",
    "            fileLink = os.path.join(foldLink, f)\n",
    "            truthful_reviews_link.append(fileLink)\n",
    "\n",
    "for fold in os.listdir(truthful_neg):\n",
    "    foldLink = os.path.join(truthful_neg, fold)\n",
    "    if os.path.isdir(foldLink):\n",
    "        for f in os.listdir(foldLink):\n",
    "            fileLink = os.path.join(foldLink, f)\n",
    "            truthful_reviews_link.append(fileLink)\n",
    "\n",
    "deceptive_reviews_link = []\n",
    "\n",
    "for fold in os.listdir(deceptive_pos):\n",
    "    foldLink = os.path.join(deceptive_pos, fold)\n",
    "    if os.path.isdir(foldLink):\n",
    "        for f in os.listdir(foldLink):\n",
    "            fileLink = os.path.join(foldLink, f)\n",
    "            deceptive_reviews_link.append(fileLink)\n",
    "\n",
    "for fold in os.listdir(deceptive_neg):\n",
    "    foldLink = os.path.join(deceptive_neg, fold)\n",
    "    if os.path.isdir(foldLink):\n",
    "        for f in os.listdir(foldLink):\n",
    "            fileLink = os.path.join(foldLink, f)\n",
    "            deceptive_reviews_link.append(fileLink)\n",
    "        \n",
    "print('Number of truthfuls reviews ', len(truthful_reviews_link))\n",
    "print('Number of deceptives reviews ', len(deceptive_reviews_link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of files is  1600\n",
      "The total number of words in the files is  253157\n",
      "Vocabulary size is  9687\n",
      "The average number of words in the files is 158.223125\n"
     ]
    }
   ],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def handleFile(filePath):\n",
    "    with open(filePath, \"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        file_voc = []\n",
    "        file_numWords = 0\n",
    "        for line in lines:\n",
    "            cleanedLine = clean_str(line)\n",
    "            cleanedLine = cleanedLine.strip()\n",
    "            cleanedLine = cleanedLine.lower()\n",
    "            words = cleanedLine.split(' ')\n",
    "            file_numWords = file_numWords + len(words)\n",
    "            file_voc.extend(words)\n",
    "    return file_voc, file_numWords\n",
    "\n",
    "\n",
    "allFilesLinks = truthful_reviews_link + deceptive_reviews_link\n",
    "vocabulary = []\n",
    "numWords = []\n",
    "for fileLink in allFilesLinks:\n",
    "    file_voc, file_numWords = handleFile(fileLink)\n",
    "    vocabulary.extend(file_voc)\n",
    "    numWords.append(file_numWords)\n",
    "\n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "print('The total number of files is ', len(numWords))\n",
    "print('The total number of words in the files is ', sum(numWords))\n",
    "print('Vocabulary size is ', len(vocabulary))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 2)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "def convertFileToArray(filePath):\n",
    "    s = \"\"\n",
    "    with open(filePath, \"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        for line in lines:\n",
    "            cleanedLine = clean_str(line)\n",
    "            cleanedLine = cleanedLine.strip()\n",
    "            cleanedLine = cleanedLine.lower()\n",
    "            s += cleanedLine\n",
    "    return s\n",
    "\n",
    "totalFiles = len(truthful_reviews_link) + len(deceptive_reviews_link)\n",
    "idsMatrix = np.ndarray(shape=(totalFiles, MAX_SEQ_LENGTH), dtype='int32')\n",
    "#dataMatrix = np.ndarray(shape=(totalFiles,1),dtype='object')\n",
    "dataMatrix = []\n",
    "#labels = np.ndarray(shape=(totalFiles, 2), dtype='int32')\n",
    "labelsMatrix = []\n",
    "counter = 0\n",
    "\n",
    "for filePath in truthful_reviews_link:\n",
    "    dataMatrix.append(convertFileToArray(filePath))\n",
    "    labelsMatrix.append(1)\n",
    "  \n",
    "\n",
    "for filePath in deceptive_reviews_link:\n",
    "    dataMatrix.append(convertFileToArray(filePath))\n",
    "    labelsMatrix.append(0)\n",
    "\n",
    "dict_reviewLabels = {'review': dataMatrix,'labels': labelsMatrix}\n",
    "df_reviewLabels = pd.DataFrame(dict_reviewLabels)\n",
    "df_reviewLabels.head(2)\n",
    "\n",
    "\n",
    "\n",
    "macronum=sorted(set(df_reviewLabels['labels']))\n",
    "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
    "\n",
    "\n",
    "def fun(i):\n",
    "    return macro_to_id[i]\n",
    "\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "df_reviewLabels.iloc[:,0]=df_reviewLabels.iloc[:,0].apply(fun)\n",
    "df_reviewLabels.head(2)\n",
    "\n",
    "\n",
    "\n",
    "print(df_reviewLabels.shape)\n",
    "# a list contains each review as a list \n",
    "balanced_texts = []\n",
    "balanced_labels = []\n",
    "\n",
    "for i in range(len(df_reviewLabels)):\n",
    "    balanced_texts.append(df_reviewLabels.iloc[i,1])\n",
    "    balanced_labels.append(df_reviewLabels.iloc[i,0])\n",
    " \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=\" \")#20000\n",
    "tokenizer.fit_on_texts(balanced_texts)\n",
    "sequences = tokenizer.texts_to_sequences(balanced_texts)\n",
    "x = pad_sequences(sequences, maxlen=200)#300\n",
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(np.asarray(balanced_labels))\n",
    "#y = df_reviewLabels['labels'].values\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, GlobalMaxPooling1D, Conv1D, Dropout, MaxPooling1D, Dense, Embedding, LSTM, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "# Build embedding layers with weights initialized from each model\n",
    "googlenews_w2v_size = 300\n",
    "googlenews_w2v_matrix = np.zeros((len(word_index) + 1, googlenews_w2v_size))\n",
    "for word,i in word_index.items():\n",
    "    try:\n",
    "        if word in w2v_model.vocab:\n",
    "            googlenews_w2v_matrix[i] = w2v_model[word]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "googlenews_w2v_emb = Embedding(len(word_index)+1,\n",
    "\n",
    "                            googlenews_w2v_size,\n",
    "\n",
    "                            weights=[googlenews_w2v_matrix],\n",
    "\n",
    "                            input_length=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(0.2 * x.shape[0])\n",
    "\n",
    "x_train = x[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = x[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 300)          2904900   \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 50)                17550     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,922,552\n",
      "Trainable params: 2,922,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 768 samples, validate on 512 samples\n",
      "Epoch 1/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6956 - acc: 0.4883 - val_loss: 0.6934 - val_acc: 0.5039\n",
      "Epoch 2/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6766 - acc: 0.5964 - val_loss: 0.6924 - val_acc: 0.5039\n",
      "Epoch 3/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6618 - acc: 0.6576 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 4/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6438 - acc: 0.7135 - val_loss: 0.6919 - val_acc: 0.5078\n",
      "Epoch 5/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6249 - acc: 0.7370 - val_loss: 0.6921 - val_acc: 0.5117\n",
      "Epoch 6/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.6045 - acc: 0.7513 - val_loss: 0.6938 - val_acc: 0.5176\n",
      "Epoch 7/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.5817 - acc: 0.7812 - val_loss: 0.6941 - val_acc: 0.5313\n",
      "Epoch 8/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.5482 - acc: 0.7982 - val_loss: 0.7004 - val_acc: 0.5391\n",
      "Epoch 9/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.5046 - acc: 0.8242 - val_loss: 0.7062 - val_acc: 0.5566\n",
      "Epoch 10/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4629 - acc: 0.8437 - val_loss: 0.7058 - val_acc: 0.5605\n",
      "Epoch 11/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.4074 - acc: 0.8464 - val_loss: 0.7080 - val_acc: 0.5684\n",
      "Epoch 12/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.3755 - acc: 0.8880 - val_loss: 0.7449 - val_acc: 0.5449\n",
      "Epoch 13/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.3179 - acc: 0.8815 - val_loss: 0.7462 - val_acc: 0.5723\n",
      "Epoch 14/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.2810 - acc: 0.9401 - val_loss: 0.7710 - val_acc: 0.5762\n",
      "Epoch 15/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.2157 - acc: 0.9323 - val_loss: 0.8631 - val_acc: 0.5664\n",
      "Epoch 16/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.1855 - acc: 0.9492 - val_loss: 0.8361 - val_acc: 0.5938\n",
      "Epoch 17/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.1414 - acc: 0.9701 - val_loss: 0.9333 - val_acc: 0.5859\n",
      "Epoch 18/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.1195 - acc: 0.9648 - val_loss: 0.9242 - val_acc: 0.5957\n",
      "Epoch 19/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0882 - acc: 0.9844 - val_loss: 0.9087 - val_acc: 0.6055\n",
      "Epoch 20/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0910 - acc: 0.9818 - val_loss: 0.9987 - val_acc: 0.5937\n",
      "Epoch 21/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0613 - acc: 0.9896 - val_loss: 1.0510 - val_acc: 0.5840\n",
      "Epoch 22/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0457 - acc: 0.9961 - val_loss: 1.0354 - val_acc: 0.5977\n",
      "Epoch 23/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0368 - acc: 0.9961 - val_loss: 1.2272 - val_acc: 0.5742\n",
      "Epoch 24/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0314 - acc: 0.9935 - val_loss: 1.2956 - val_acc: 0.5723\n",
      "Epoch 25/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0226 - acc: 0.9987 - val_loss: 1.2118 - val_acc: 0.5918\n",
      "Epoch 26/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 1.3412 - val_acc: 0.5723\n",
      "Epoch 27/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.4522 - val_acc: 0.5586\n",
      "Epoch 28/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0140 - acc: 0.9987 - val_loss: 1.3225 - val_acc: 0.5859\n",
      "Epoch 29/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 1.3329 - val_acc: 0.5918\n",
      "Epoch 30/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.3676 - val_acc: 0.5859\n",
      "Epoch 31/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.5203 - val_acc: 0.5840\n",
      "Epoch 32/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.9974 - val_loss: 1.4375 - val_acc: 0.5840\n",
      "Epoch 33/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.4022 - val_acc: 0.5898\n",
      "Epoch 34/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.4597 - val_acc: 0.5859\n",
      "Epoch 35/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.6446 - val_acc: 0.5684\n",
      "Epoch 36/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 0.9974 - val_loss: 1.5243 - val_acc: 0.5742\n",
      "Epoch 37/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.4698 - val_acc: 0.5820\n",
      "Epoch 38/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.5991 - val_acc: 0.5625\n",
      "Epoch 39/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.6571 - val_acc: 0.5625\n",
      "Epoch 40/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 1.6293 - val_acc: 0.5723\n",
      "Epoch 41/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.5771 - val_acc: 0.5840\n",
      "Epoch 42/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 1.7077 - val_acc: 0.5723\n",
      "Epoch 43/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.9039 - val_acc: 0.5664\n",
      "Epoch 44/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.6054 - val_acc: 0.5586\n",
      "Epoch 45/45\n",
      "768/768 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.5658 - val_acc: 0.5508\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "#simple rnn\n",
    "model = Sequential()\n",
    "model.add(googlenews_w2v_emb)\n",
    "model.add(SimpleRNN(units=50,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(len(macronum)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n",
    "opt = optimizers.adam(lr=0.0008)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,batch_size=200,epochs=45,validation_split=0.4,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8203\n",
      "Testing Accuracy:  0.5250\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(x_val, y_val, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "python_custom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4781551 entries, 0 to 4781550\n",
      "Data columns (total 6 columns):\n",
      "business_id    object\n",
      "date           object\n",
      "review_id      object\n",
      "stars          float64\n",
      "text           object\n",
      "user_id        object\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 218.9+ MB\n"
     ]
    }
   ],
   "source": [
    "path='/home/drallab/datamining/Yelp_Sentiment_Analysis-master/data/review_subset.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.iloc[:,3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4781551 entries, 0 to 4781550\n",
      "Data columns (total 2 columns):\n",
      "stars    float64\n",
      "text     object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 73.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()\n",
    "df1 = df1[(df1.stars == 5) | (df1.stars == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = shuffle(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3026342 entries, 2547031 to 4010462\n",
      "Data columns (total 2 columns):\n",
      "stars    float64\n",
      "text     object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 69.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2547031</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great sushi! Even better staff. It's a great p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440921</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Madness Cup is conveniently by the Box Office ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Extremely flavorless and hard to eat chicken w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388380</th>\n",
       "      <td>1.0</td>\n",
       "      <td>In a strange set of circumstances, this Pizza ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000918</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This was my second time to Osaka and I (we) re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stars                                               text\n",
       "2547031    5.0  Great sushi! Even better staff. It's a great p...\n",
       "4440921    5.0  Madness Cup is conveniently by the Box Office ...\n",
       "3103894    1.0  Extremely flavorless and hard to eat chicken w...\n",
       "2388380    1.0  In a strange set of circumstances, this Pizza ...\n",
       "2000918    5.0  This was my second time to Osaka and I (we) re..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df1['text']\n",
    "y_data = df1['stars']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3026342,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3026342,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/5.1.0/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2118439,)\n",
      "(907903,)\n",
      "(2118439,)\n",
      "(907903,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X_data,y_data,test_size =0.3,random_state=42)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2118439x342158 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 136958109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer shall be used to work on text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize Test data\n",
    "X_test_dtm = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode 1 and 5 rating\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "y_train=lb.fit_transform(y_train)\n",
    "y_test=lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/5.1.0/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([ 1. ,  1.2, ..., 19.6, 19.8]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using GridsearchCV for parameter selection and tuning.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid={'C':np.arange(1,20,0.2),'penalty':['l1','l2']},cv=10)\n",
    "grid.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict \n",
    "grid.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best params\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974358974358975"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Score\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4.19, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(C=4.19,penalty='l2')\n",
    "log_reg.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5. 5. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "logr_pred = log_reg.predict(X_test_dtm)\n",
    "print (logr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 1. 5. 1. 5. 1. 1. 5. 5. 5. 1. 1. 5. 1.\n",
      " 5.]\n",
      "True      3555780    5.0\n",
      "4189475    5.0\n",
      "491733     5.0\n",
      "1217858    5.0\n",
      "397618     5.0\n",
      "1186835    5.0\n",
      "3284383    5.0\n",
      "3245477    5.0\n",
      "2507024    5.0\n",
      "4779129    5.0\n",
      "4644919    5.0\n",
      "1823679    1.0\n",
      "1133311    5.0\n",
      "1901053    1.0\n",
      "4445984    5.0\n",
      "2570387    1.0\n",
      "2320451    1.0\n",
      "1406279    5.0\n",
      "2063675    5.0\n",
      "1148738    5.0\n",
      "4342600    1.0\n",
      "2416826    1.0\n",
      "3030190    5.0\n",
      "2921277    1.0\n",
      "340148     5.0\n",
      "Name: stars, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#lets analyse 25 elements of predicted and test y labels , 0 means 1 rating and 1 means 5 rating \n",
    "print('Predicted',(logr_pred[:25]))\n",
    "print('True     ',(y_test[:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9807633634870686\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print ('accuracy score',metrics.accuracy_score(y_test,logr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix \n",
      " [[213764   9740]\n",
      " [  7725 676674]]\n"
     ]
    }
   ],
   "source": [
    "#Lets see the confusion metrix \n",
    "conf_matrix=metrics.confusion_matrix(y_test,logr_pred)\n",
    "print ('confusion matrix \\n',conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>213764</td>\n",
       "      <td>9740</td>\n",
       "      <td>223504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>7725</td>\n",
       "      <td>676674</td>\n",
       "      <td>684399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>221489</td>\n",
       "      <td>686414</td>\n",
       "      <td>907903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     1.0     5.0     All\n",
       "True                             \n",
       "1.0        213764    9740  223504\n",
       "5.0          7725  676674  684399\n",
       "All        221489  686414  907903"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize\n",
    "\n",
    "pd.crosstab(y_test, logr_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score 0.9564213615863698\n"
     ]
    }
   ],
   "source": [
    "#Sensitivity : is the classifier to detecting positive instances , also True Positive Rate\" or \"Recall\"\n",
    "recall_logr= metrics.recall_score(y_test,logr_pred)\n",
    "print ('Recall score',recall_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score 0.9651224214295067\n"
     ]
    }
   ],
   "source": [
    "#Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "#How \"precise\" is the classifier when predicting positive instances?\n",
    "\n",
    "Precision_logr= metrics.precision_score(y_test,logr_pred)\n",
    "print('Precision Score', Precision_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text, dtype: object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print rating 1 reviews which are falsely callisified as positive i.e rating 5 ,diplay False Postive review comments\n",
    "X_test[(logr_pred == 1) & (y_test == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text, dtype: object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print rating 5 reviews which are falsely callisified as negative i.e rating 1,diplay True Negative review comments\n",
    "X_test[(logr_pred == 0) & (y_test == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I purchased a used safe on Craigslist.  Not just any safe mind you.  Oh no, I HAD to have the super high security 4000 lb bank safe ... especially at the dirt cheap price it was listed.\\n\\nLet me say that again - FOUR THOUSAND POUNDS.  Two tons.  About the same as a Toyota Highlander.  5 feet tall, 4 feet wide, and about 35 inches deep.\\n\\nI spent several days calling around to places to get it moved.  No one wanted to touch this thing.  Then I called The Safe Keeper.\\n\\nDon (the owner) agreed to do it for $800.  More than I wanted to spend, because I'm a cheapskate.  I finally agreed since no one else would take the job.\\n\\nI'M GLAD I DID!!\\n\\nDon and 3 of his guys picked it up from a warehouse near the strip, moved it to my home in Centennial.  They used two pallet jacks, an assortment of wood blocks and chocks, and floor coverings.  Four turns and one 36 inch wide doorway later, they had it placed EXACTLY where I wanted it.  No scuffed walls.  No indentations in the linoleum.  No damage to persons or property whatsoever.  \\n\\nNot a lot impresses me.  (See my other reviews.)  But these guys did.  Folks, the whole crew were professional safe movers who worked seamlessly together.\\n\\nFIVE STARS.  ALL THE WAY.  CALL THEM WHEN YOU NEED A SAFE MOVED.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.97      0.96      0.96    223504\n",
      "        5.0       0.99      0.99      0.99    684399\n",
      "\n",
      "avg / total       0.98      0.98      0.98    907903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets print classifcation report\n",
    "class_report = metrics.classification_report(y_test,logr_pred)\n",
    "print (class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
